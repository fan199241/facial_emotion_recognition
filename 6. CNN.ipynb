{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "df = pd.read_csv('norm_selected_pixels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px_1456</th>\n",
       "      <th>px_1408</th>\n",
       "      <th>px_1504</th>\n",
       "      <th>px_1503</th>\n",
       "      <th>px_1455</th>\n",
       "      <th>px_1551</th>\n",
       "      <th>px_1552</th>\n",
       "      <th>px_1361</th>\n",
       "      <th>px_1360</th>\n",
       "      <th>px_1409</th>\n",
       "      <th>...</th>\n",
       "      <th>px_82</th>\n",
       "      <th>px_12</th>\n",
       "      <th>px_14</th>\n",
       "      <th>px_29</th>\n",
       "      <th>px_1217</th>\n",
       "      <th>px_1612</th>\n",
       "      <th>px_36</th>\n",
       "      <th>px_28</th>\n",
       "      <th>px_83</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.850980</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.486275</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.486275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    px_1456   px_1408   px_1504   px_1503   px_1455   px_1551   px_1552  \\\n",
       "0  0.654902  0.674510  0.639216  0.635294  0.654902  0.627451  0.619608   \n",
       "1  0.360784  0.388235  0.349020  0.337255  0.439216  0.243137  0.384314   \n",
       "2  0.650980  0.772549  0.670588  0.556863  0.611765  0.772549  0.764706   \n",
       "3  0.482353  0.486275  0.529412  0.584314  0.643137  0.592157  0.588235   \n",
       "4  0.580392  0.552941  0.603922  0.580392  0.588235  0.556863  0.600000   \n",
       "\n",
       "    px_1361   px_1360   px_1409  ...     px_82     px_12     px_14     px_29  \\\n",
       "0  0.698039  0.701961  0.662745  ...  0.654902  0.349020  0.474510  0.670588   \n",
       "1  0.376471  0.364706  0.450980  ...  0.533333  0.600000  0.678431  0.631373   \n",
       "2  0.654902  0.800000  0.533333  ...  0.792157  0.152941  0.541176  0.862745   \n",
       "3  0.513725  0.435294  0.529412  ...  0.384314  0.125490  0.082353  0.435294   \n",
       "4  0.501961  0.552941  0.486275  ...  0.662745  0.011765  0.090196  0.596078   \n",
       "\n",
       "    px_1217   px_1612     px_36     px_28     px_83  emotion  \n",
       "0  0.705882  0.713725  0.443137  0.619608  0.454902        0  \n",
       "1  0.474510  0.654902  0.631373  0.650980  0.423529        0  \n",
       "2  0.980392  0.788235  0.635294  0.850980  0.682353        2  \n",
       "3  0.529412  0.482353  0.752941  0.384314  0.505882        4  \n",
       "4  0.533333  0.811765  0.325490  0.600000  0.576471        6  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.emotion\n",
    "X = df.drop('emotion',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=df['emotion'], random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px_1456</th>\n",
       "      <th>px_1408</th>\n",
       "      <th>px_1504</th>\n",
       "      <th>px_1503</th>\n",
       "      <th>px_1455</th>\n",
       "      <th>px_1551</th>\n",
       "      <th>px_1552</th>\n",
       "      <th>px_1361</th>\n",
       "      <th>px_1360</th>\n",
       "      <th>px_1409</th>\n",
       "      <th>...</th>\n",
       "      <th>px_1746</th>\n",
       "      <th>px_82</th>\n",
       "      <th>px_12</th>\n",
       "      <th>px_14</th>\n",
       "      <th>px_29</th>\n",
       "      <th>px_1217</th>\n",
       "      <th>px_1612</th>\n",
       "      <th>px_36</th>\n",
       "      <th>px_28</th>\n",
       "      <th>px_83</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.262745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20895</th>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.121569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.690196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18388</th>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.682353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        px_1456   px_1408   px_1504   px_1503   px_1455   px_1551   px_1552  \\\n",
       "17374  0.815686  0.784314  0.564706  0.576471  0.823529  0.729412  0.780392   \n",
       "20895  0.615686  0.647059  0.568627  0.517647  0.556863  0.494118  0.529412   \n",
       "7762   0.470588  0.505882  0.392157  0.329412  0.403922  0.298039  0.192157   \n",
       "18388  0.780392  0.784314  0.772549  0.768627  0.780392  0.756863  0.772549   \n",
       "10101  0.713725  0.737255  0.682353  0.662745  0.709804  0.623529  0.643137   \n",
       "\n",
       "        px_1361   px_1360   px_1409  ...   px_1746     px_82     px_12  \\\n",
       "17374  0.784314  0.776471  0.792157  ...  0.882353  0.176471  0.105882   \n",
       "20895  0.701961  0.666667  0.701961  ...  0.454902  0.141176  0.121569   \n",
       "7762   0.537255  0.498039  0.501961  ...  0.282353  0.670588  0.780392   \n",
       "18388  0.764706  0.788235  0.756863  ...  0.658824  0.713725  0.678431   \n",
       "10101  0.745098  0.737255  0.733333  ...  0.443137  0.658824  0.521569   \n",
       "\n",
       "          px_14     px_29   px_1217   px_1612     px_36     px_28     px_83  \n",
       "17374  0.121569  0.309804  0.678431  0.741176  0.274510  0.219608  0.262745  \n",
       "20895  0.207843  0.145098  0.654902  0.745098  0.101961  0.141176  0.121569  \n",
       "7762   0.745098  0.670588  0.654902  0.168627  0.686275  0.658824  0.690196  \n",
       "18388  0.713725  0.788235  0.792157  0.749020  0.588235  0.800000  0.682353  \n",
       "10101  0.607843  0.729412  0.764706  0.576471  0.596078  0.745098  0.627451  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px_1456</th>\n",
       "      <th>px_1408</th>\n",
       "      <th>px_1504</th>\n",
       "      <th>px_1503</th>\n",
       "      <th>px_1455</th>\n",
       "      <th>px_1551</th>\n",
       "      <th>px_1552</th>\n",
       "      <th>px_1361</th>\n",
       "      <th>px_1360</th>\n",
       "      <th>px_1409</th>\n",
       "      <th>...</th>\n",
       "      <th>px_1746</th>\n",
       "      <th>px_82</th>\n",
       "      <th>px_12</th>\n",
       "      <th>px_14</th>\n",
       "      <th>px_29</th>\n",
       "      <th>px_1217</th>\n",
       "      <th>px_1612</th>\n",
       "      <th>px_36</th>\n",
       "      <th>px_28</th>\n",
       "      <th>px_83</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9780</th>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7860</th>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25340</th>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.113725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23588</th>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.188235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        px_1456   px_1408   px_1504   px_1503   px_1455   px_1551   px_1552  \\\n",
       "9780   0.125490  0.490196  0.113725  0.149020  0.117647  0.780392  0.666667   \n",
       "7860   0.847059  0.870588  0.831373  0.835294  0.858824  0.819608  0.819608   \n",
       "25340  0.172549  0.258824  0.250980  0.219608  0.152941  0.250980  0.258824   \n",
       "5006   0.368627  0.384314  0.317647  0.337255  0.298039  0.317647  0.211765   \n",
       "23588  0.392157  0.505882  0.454902  0.388235  0.474510  0.380392  0.454902   \n",
       "\n",
       "        px_1361   px_1360   px_1409  ...   px_1746     px_82     px_12  \\\n",
       "9780   0.721569  0.752941  0.643137  ...  0.211765  0.639216  0.737255   \n",
       "7860   0.866667  0.878431  0.858824  ...  0.815686  0.576471  0.670588   \n",
       "25340  0.356863  0.349020  0.325490  ...  0.290196  0.109804  0.086275   \n",
       "5006   0.333333  0.258824  0.372549  ...  0.070588  0.305882  0.000000   \n",
       "23588  0.529412  0.639216  0.364706  ...  0.552941  0.290196  0.329412   \n",
       "\n",
       "          px_14     px_29   px_1217   px_1612     px_36     px_28     px_83  \n",
       "9780   0.764706  0.745098  0.270588  0.921569  0.678431  0.721569  0.647059  \n",
       "7860   0.686275  0.654902  0.866667  0.466667  0.447059  0.670588  0.533333  \n",
       "25340  0.090196  0.117647  0.262745  0.282353  0.101961  0.101961  0.113725  \n",
       "5006   0.172549  0.176471  0.533333  0.235294  0.247059  0.121569  0.294118  \n",
       "23588  0.443137  0.517647  0.603922  0.678431  0.094118  0.533333  0.188235  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25120, 149) (25120,) (10767, 149) (10767,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f868e7e5c88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f867789f080>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build BP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-dded45c98136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: %.2f%% (%.2f)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m     90\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3495\u001b[0m     \"\"\"\n\u001b[1;32m   3496\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3497\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3499\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3403\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3405\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3406\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3548\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3549\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3550\u001b[0;31m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3552\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3118\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 构建模型    *输入层（4个输入）---> 隐藏层（4个神经元）---> 隐藏层（6个神经元）---> 输出层（3个输出）\n",
    "def create_model(optimizer='adam', init='glorot_uniform'):\n",
    "    # 构建模型    *输入层（4个输入）---> 隐藏层（4个神经元）---> 隐藏层（6个神经元）---> 输出层（3个输出）\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=150, activation='relu', input_dim=149, kernel_initializer=init))\n",
    "    model.add(Dense(units=10, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(units=7, activation='softmax', kernel_initializer=init))\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print('Accuracy: %.2f%% (%.2f)' % (results.mean()*100, results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decision tree model\n",
    "dt = DecisionTreeClassifier(criterion='gini')\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 5 0 ... 3 6 6]\n"
     ]
    }
   ],
   "source": [
    "y_pred = dt.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.28160118881768365\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "scores = dt.score(X_test,y_test)\n",
    "print('accuracy:',scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[327,  19, 206, 328, 238, 122, 246],\n",
       "       [ 19,  46,  10,  33,  27,  15,  14],\n",
       "       [187,  20, 384, 308, 234, 127, 276],\n",
       "       [330,  46, 347, 928, 441, 230, 375],\n",
       "       [253,  25, 264, 405, 430, 134, 312],\n",
       "       [103,  15, 133, 171, 131, 448, 200],\n",
       "       [252,  26, 265, 367, 309, 172, 469]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327</td>\n",
       "      <td>19</td>\n",
       "      <td>206</td>\n",
       "      <td>328</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>246</td>\n",
       "      <td>1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>187</td>\n",
       "      <td>20</td>\n",
       "      <td>384</td>\n",
       "      <td>308</td>\n",
       "      <td>234</td>\n",
       "      <td>127</td>\n",
       "      <td>276</td>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>330</td>\n",
       "      <td>46</td>\n",
       "      <td>347</td>\n",
       "      <td>928</td>\n",
       "      <td>441</td>\n",
       "      <td>230</td>\n",
       "      <td>375</td>\n",
       "      <td>2697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>253</td>\n",
       "      <td>25</td>\n",
       "      <td>264</td>\n",
       "      <td>405</td>\n",
       "      <td>430</td>\n",
       "      <td>134</td>\n",
       "      <td>312</td>\n",
       "      <td>1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>103</td>\n",
       "      <td>15</td>\n",
       "      <td>133</td>\n",
       "      <td>171</td>\n",
       "      <td>131</td>\n",
       "      <td>448</td>\n",
       "      <td>200</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>252</td>\n",
       "      <td>26</td>\n",
       "      <td>265</td>\n",
       "      <td>367</td>\n",
       "      <td>309</td>\n",
       "      <td>172</td>\n",
       "      <td>469</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1471</td>\n",
       "      <td>197</td>\n",
       "      <td>1609</td>\n",
       "      <td>2540</td>\n",
       "      <td>1810</td>\n",
       "      <td>1248</td>\n",
       "      <td>1892</td>\n",
       "      <td>10767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0    1     2     3     4     5     6    All\n",
       "True                                                     \n",
       "0           327   19   206   328   238   122   246   1486\n",
       "1            19   46    10    33    27    15    14    164\n",
       "2           187   20   384   308   234   127   276   1536\n",
       "3           330   46   347   928   441   230   375   2697\n",
       "4           253   25   264   405   430   134   312   1823\n",
       "5           103   15   133   171   131   448   200   1201\n",
       "6           252   26   265   367   309   172   469   1860\n",
       "All        1471  197  1609  2540  1810  1248  1892  10767"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(y_test, y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.22      0.22      1486\n",
      "           1       0.23      0.28      0.25       164\n",
      "           2       0.24      0.25      0.24      1536\n",
      "           3       0.37      0.34      0.35      2697\n",
      "           4       0.24      0.24      0.24      1823\n",
      "           5       0.36      0.37      0.37      1201\n",
      "           6       0.25      0.25      0.25      1860\n",
      "\n",
      "   micro avg       0.28      0.28      0.28     10767\n",
      "   macro avg       0.27      0.28      0.28     10767\n",
      "weighted avg       0.28      0.28      0.28     10767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
